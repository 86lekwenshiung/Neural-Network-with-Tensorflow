{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Natural_Language_Processing in Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWiEGueQ9dNAVj62V+O4kf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/86lekwenshiung/Neural-Network-with-Tensorflow/blob/main/07_Natural_Language_Processing_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eim5-c54xWMJ"
      },
      "source": [
        "# 0.0 Natural Language Processing in Tensorflow\n",
        "___\n",
        "\n",
        "The main goal of natural language processing (NLP) is to derive information from natural language.\n",
        "Natural language is a broad term but you can consider it to cover any of the following:\n",
        "* Text (such as that contained in an email, blog post, book, Tweet)\n",
        "* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
        "\n",
        "**What is NLP used for?**\n",
        "\n",
        "Natural Language Processing is the driving force behind the following common applications:\n",
        "* Language translation applications such as Google Translate\n",
        "* Word Processors such as Microsoft Word and Grammarly that employ NLP to check grammatical accuracy of texts.\n",
        "* Interactive Voice Response (IVR) applications used in call centers to respond to certain users’ requests.\n",
        "* Personal assistant applications such as OK Google, Siri, Cortana, and Alexa.\n",
        "\n",
        "**Workflow**\n",
        "```\n",
        "Download text -> Visualize Text -> turn into numbers (tokenization , embedding) -> build a model -> train the model to find patterns -> compare model -> ensemble model\n",
        "```\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems(seq2seq)\n",
        "\n",
        "**Typical Architecture of a RNN**\n",
        "\n",
        "| Hyperparameter/Layer type | What does it do? | Typical values |\n",
        "|---|---|---|\n",
        "| Input text(s) | Target texts/sequences you'd like to discover patterns in | Whatever you can represent as text or a sequence |\n",
        "| Input layer | Takes in target sequence | input_shape = [batch_size, embedding_size] or [batch_size , sequence_shape] |\n",
        "| Text Vectorisation layer | Maps input sequence to layers | Multiple, can create with tf.keras.layers.preprocessing.TextVectorisation |\n",
        "| Embedding | Turn mapping of text vectors to embedding matrix | Multiple, can create with tf.keras.layers.Embedding |\n",
        "| RNN Cells | Find Pattern in Sequences | SimpleRNN , LSTM , GRU |\n",
        "| Hidden activation | Adds non-linearity to learned features (non-straight lines) | Usually Tanh (tf.keras.activations.tanh) |\n",
        "| Pooling layer | Reduces the dimensionality of learned image features | Average (tf.keras.layers.GlobalAveragePooling1D) or Max (tf.keras.layers.GlobalMaxPool1D) |\n",
        "| Fully connected layer | Further refines learned features from convolution layers | tf.keras.layers.Dense |\n",
        "| Output layer | Takes learned features and outputs them in shape of target labels | output_shape = [number_of_classes] (e.g. disaster , Not Disaster) |\n",
        "| Output activation | Adds non-linearities to output layer | tf.keras.activations.sigmoid (binary classification) or tf.keras.activations.softmax |\n",
        "\n",
        "\n",
        "`source` : \n",
        "* https://towardsdatascience.com/whatnlpscientistsdo-905aa987c5c0\n",
        "* https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32\n",
        "* https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFzwy8N6F6Go"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3kKLkexpZg5"
      },
      "source": [
        "# 0.5 General Function\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m6S7yBWpcko"
      },
      "source": [
        "### TensorBoard Callbacks\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lAtiV6Pphsy"
      },
      "source": [
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name , experiment_name):\n",
        "  log_dir = dir_name +'/' + experiment_name +'/' +datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
        "  print(f'Saving Tensorboard log files to {log_dir}')\n",
        "  return tensorboard_callback"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMCz1kyYqGor"
      },
      "source": [
        "### Classification Evaluation Metrics\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Sw0p_RqSna"
      },
      "source": [
        "def eval_classification(y_true , y_pred):\n",
        "\n",
        "  from sklearn.metrics import accuracy_score , precision_score , recall_score , f1_score\n",
        "\n",
        "  # Define Scoring variables\n",
        "  accuracy = accuracy_score(y_true , y_pred)\n",
        "  precision = precision_score(y_true , y_pred)\n",
        "  recall = recall_score(y_true , y_pred)\n",
        "  f1_score = f1_score(y_true , y_pred)\n",
        "\n",
        "  score_dict = {'Accuracy' : accuracy,\n",
        "                'Precision' : precision,\n",
        "                'Recall' : recall,\n",
        "                'F1 Score' : f1_score}\n",
        "\n",
        "  return score_dict"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmsa-gdhyC96"
      },
      "source": [
        "# 1.0 Getting Data from kaggle (Natural Language Processing with Disaster Tweets)\n",
        "___\n",
        "\n",
        "source : https://www.kaggle.com/philculliton/nlp-getting-started-tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqcke9JRFHR1",
        "outputId": "8481e3fb-4ef3-4405-a2c8-8a0061a4c825"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-26 18:12:00--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.128, 108.177.96.128, 108.177.119.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip.3’\n",
            "\n",
            "\r          nlp_getti   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-08-26 18:12:00 (81.5 MB/s) - ‘nlp_getting_started.zip.3’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr-wTtW6F4CP"
      },
      "source": [
        "# Unzip file\n",
        "zip_ref = zipfile.ZipFile('nlp_getting_started.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJbl6bVkGPlB"
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjCOXeq2paFC"
      },
      "source": [
        "### 1.1 Visualising Data\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "KIwlOi_PGx-g",
        "outputId": "0948b777-3a53-48b6-b715-b936ebf6779d"
      },
      "source": [
        "# Checking Training Data\n",
        "df_train.head()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Gh3_6aYfiWDp",
        "outputId": "81fe422b-ddee-4bf1-f4c0-4261bc695607"
      },
      "source": [
        "df_train = df_train.sample(frac = 1 , random_state = 42)\n",
        "df_train.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SruLz4mQGy24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f1bbd648-50dc-4406-c95e-914b5db8c014"
      },
      "source": [
        "# Checking Test Data\n",
        "df_test.head()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-_KqfbyiPap",
        "outputId": "2de8af33-0134-4990-d016-aaf8745187a5"
      },
      "source": [
        "# Target True : False Ratio\n",
        "df_train['target'].value_counts(normalize = True)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.57034\n",
              "1    0.42966\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "lX2gUbWPltwJ",
        "outputId": "c4663530-7db9-4882-dff1-48d408c4bed8"
      },
      "source": [
        "random_index = random.randint(0 , len(df_train))\n",
        "df_train[['text' , 'target']].head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  target\n",
              "2644  So you have a new weapon that can cause un-ima...       1\n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0\n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1\n",
              "132   Aftershock back to school kick off was great. ...       0\n",
              "6845  in response to trauma Children of Addicts deve...       0"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb6c_PEhjDTZ",
        "outputId": "3b71fd3d-8be7-4b58-b930-d5ffb39d6024"
      },
      "source": [
        "random_index = random.randint(0 , len(df_train))\n",
        "\n",
        "for row in df_train[['text' , 'target']][random_index : random_index +5].itertuples():\n",
        "  _ , text , target = row\n",
        "\n",
        "  print(f\"Target: {target}\" , \"(Disaster)\" if target > 0 else \"(Not Disaster)\")\n",
        "  print(f'Text: {text}')\n",
        "  print('-------\\n')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1 (Disaster)\n",
            "Text: On the sneak America has us spoiled. A natural disaster will humble niggas.\n",
            "-------\n",
            "\n",
            "Target: 0 (Not Disaster)\n",
            "Text: Kids are inundated with images and information online and in media and have no way to deconstruct. - Kerri Sackville #TMS7\n",
            "-------\n",
            "\n",
            "Target: 1 (Disaster)\n",
            "Text: Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/985DwWPdEt\n",
            "-------\n",
            "\n",
            "Target: 1 (Disaster)\n",
            "Text: Heat wave in WB heavy losses and no compensations (report) -  http://t.co/wMDihdiz1r (via PalinfoEn)   #Palestine\n",
            "-------\n",
            "\n",
            "Target: 1 (Disaster)\n",
            "Text: @sonofbobBOB @Shimmyfab @trickxie usually I'd agree. Once the whole chopping heads off throwing gays off rooftops &amp; suicide bombing start\n",
            "-------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz18FeIVjwGH"
      },
      "source": [
        "### 1.2 Data Split Training and Validation\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUrB2HkjqMWi"
      },
      "source": [
        "# Define X and y variables\n",
        "train = df_train['text'].to_numpy()\n",
        "val = df_train['target'].to_numpy()"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF9ODPAKpoVy"
      },
      "source": [
        "train_sentences , val_sentences ,train_label , val_label = train_test_split(train , val , test_size = 0.1 , random_state  = 42)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIEaw6E2qrzS",
        "outputId": "24f49c6c-ec62-406f-caaa-19a5b21442c2"
      },
      "source": [
        "print(f'Train Sentence: {train_sentences.shape}')\n",
        "print(f'Val Sentence: {val_sentences.shape}')\n",
        "print(f'Train Label: {train_label.shape}')\n",
        "print(f'Val Label: {val_label.shape}')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Sentence: (6851,)\n",
            "Val Sentence: (762,)\n",
            "Train Label: (6851,)\n",
            "Val Label: (762,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxMdAYVZra8K"
      },
      "source": [
        "### 1.3 Converting Text into Numbers\n",
        "___\n",
        "\n",
        "* Tokenization : Straight mapping from token to number , however model can get very big as no. of words increases.\n",
        "* Embedding : Representation by vector , weighted matrix. Richer representation of relationship between tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X4mYslKCiwv"
      },
      "source": [
        "#### 1.3.1 Tokenization\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ShPUeyvrsJi"
      },
      "source": [
        "# # Default Setting of TextVectorisation\n",
        "# text_vectorizer = TextVectorization(max_tokens = None,\n",
        "#                                     standardize = 'lower_and_strip_punctuation',\n",
        "#                                     split = 'whitespace',\n",
        "#                                     ngrams = None, # grouping of words\n",
        "#                                     output_mode = 'int',\n",
        "#                                     output_sequence_length = None,\n",
        "#                                     pad_to_max_tokens = True) "
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "las3jVye85oo"
      },
      "source": [
        "#   This example instantiates a `TextVectorization` layer that lowercases text, splits on whitespace, strips punctuation, and outputs integer vocab indices.\n",
        "\n",
        "max_vocab_length = 10000  # Max number of words in our vocab\n",
        "max_length = 15 # max length our sequence will be (In this case the sequence is a tweet)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length = max_length,\n",
        "                                    pad_to_max_tokens = True)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaHFUlvHoiJU"
      },
      "source": [
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQk2DAEIAU3o",
        "outputId": "802c4579-cbfd-4adf-c7ca-eb9bffbd4e44"
      },
      "source": [
        "# Our max_length is set as 15 and our sentence only have 7 words. The rest of the 8 remaining words are padded with 0s.\n",
        "sample_sentence = 'There is a flood in Bukit Timah'\n",
        "text_vectorizer(sample_sentence)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15,), dtype=int64, numpy=\n",
              "array([ 74,   9,   3, 232,   4,   1,   1,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw94BLWBA2OO",
        "outputId": "d3807c0e-25a2-4819-c6ce-618e15947915"
      },
      "source": [
        "# Visualing random sentence from our training dataset.\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Originial Sentence: {random_sentence}')\n",
        "print('--------')\n",
        "print(f'Vectorized Sentence: {text_vectorizer(random_sentence)}')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Originial Sentence: Goulburn man Henry Van Bilsen missing: Emergency services are searching for a Goulburn man who disappeared from hisÛ_ http://t.co/z99pKJzTRp\n",
            "--------\n",
            "Vectorized Sentence: [5549   89 5489 1929    1  373   73  327   22  669   10    3 5549   89\n",
            "   65]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCvRLlvsBtxI",
        "outputId": "cf25ab30-07ac-422e-de7b-90af3f6a00af"
      },
      "source": [
        "# Checking the unique vocabulary\n",
        "word_in_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f'Top 10 words: {word_in_vocab[:10]}')\n",
        "print(f'Bottom 10 words: {word_in_vocab[-10:]}')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 words: ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is']\n",
            "Bottom 10 words: ['painthey', 'painful', 'paine', 'paging', 'pageshi', 'pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkIGwXxaANpc"
      },
      "source": [
        "#### 1.3.2 Embedding\n",
        "___\n",
        "\n",
        "* Key Parameters for embedding layer:\n",
        "  - `input_dim` = size of our vocab\n",
        "  - `output_dim` = size of our output embedding vector. A value of 100 would mean each token get represented by a vector 100 long\n",
        "  - `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on_rl4ZmeQAy",
        "outputId": "03b93bd7-9c75-4a8f-8bf7-869aec0db410"
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim = max_vocab_length,\n",
        "                                      output_dim = 128,\n",
        "                                      input_length = max_length)\n",
        "embedding"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f062e97ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX1styRUennc",
        "outputId": "ab10385c-59f2-4a88-d432-2a05512b2762"
      },
      "source": [
        "# Visualing random sentence from our training dataset.\n",
        "random_sentence = random.choice(train_sentences)\n",
        "\n",
        "print(f'Original Sentence : {random_sentence}')\n",
        "print('--------')\n",
        "print(f'Embedded Sentence : {embedding(text_vectorizer(random_sentence)).shape}')\n",
        "print(f'Embedded Sentence : {embedding(text_vectorizer(random_sentence))}')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence : Officer Wounded Suspect Killed in Exchange of Gunfire: Richmond police officer wounded suspect killed in exc... http://t.co/zDHwRN6cZc\n",
            "--------\n",
            "Embedded Sentence : (15, 128)\n",
            "Embedded Sentence : [[-0.0239583   0.02416081 -0.00979527 ... -0.04668007 -0.01397713\n",
            "  -0.00261535]\n",
            " [ 0.03097672 -0.00587211 -0.04343293 ...  0.04963129  0.00380563\n",
            "  -0.03805446]\n",
            " [-0.01389981  0.01931682 -0.03164418 ... -0.01101432  0.02029847\n",
            "   0.01594095]\n",
            " ...\n",
            " [-0.01389981  0.01931682 -0.03164418 ... -0.01101432  0.02029847\n",
            "   0.01594095]\n",
            " [ 0.01624436  0.02262406 -0.00955763 ... -0.03733759  0.03619066\n",
            "  -0.01987487]\n",
            " [-0.01294749  0.00542659 -0.04776496 ... -0.0214572  -0.02556634\n",
            "   0.01253258]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc53FaxCetLs"
      },
      "source": [
        "### 1.4 Model 0 : Baseline Model with Naive Bayes with TF_IDF encoder\n",
        "___\n",
        "\n",
        "* Model 0 : Naive Bayes with TF-IDF encoder\n",
        "* Model 1 : Feed-Forward neural network (dense)\n",
        "* Model 2 : LSTM model (RNN)\n",
        "* Model 3 : GRU model (RNN)\n",
        "* Model 4 : Bidirectional - LSTM model (RNN)\n",
        "* Model 5 : 1D CNN\n",
        "* Model 6 : TF Hub Pretrained Feature Extractor\n",
        "* Model 7 : TF Hub Pretrained Feature Extractor with 10% data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6MvfWqqjGUL",
        "outputId": "f9ad45c2-c58c-46b2-8188-04bcf47b76fc"
      },
      "source": [
        "model_0 = Pipeline([\n",
        "                    ('tfidf' , TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    ('clf' , MultinomialNB()) #model the text\n",
        "])\n",
        "\n",
        "model_0.fit(train_sentences , train_label)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kSED-LejjpK"
      },
      "source": [
        "# Baseline model score\n",
        "model_0.score(val_sentences , val_label)\n",
        "model_0_preds = model_0.predict(val_sentences)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFvNGMtfl5aj",
        "outputId": "ed6dd541-e721-4960-8ad7-7265171cfaa2"
      },
      "source": [
        "eval_classification(y_true = val_label , y_pred = model_0_preds)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.7926509186351706,\n",
              " 'F1 Score': 0.734006734006734,\n",
              " 'Precision': 0.8861788617886179,\n",
              " 'Recall': 0.6264367816091954}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYL7vKHCmAk6"
      },
      "source": [
        "### 1.5 Model 1 : Feed Forward Neural Network\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8frA0hfog6a"
      },
      "source": [
        "# Build model with the functional API\n",
        "\n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string) # inputs are 1-D strings\n",
        "x = text_vectorizer(inputs) # turn the text into numbers\n",
        "x = embedding(x) # create an embedding \n",
        "# x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token\n",
        "outputs = layers.Dense(1 , activation = 'sigmoid')(x)\n",
        "model_1 = tf.keras.Model(inputs = inputs , outputs = outputs , name ='model_1')"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a4x8O6tro-K",
        "outputId": "8ef62325-eb3e-45b5-cab9-99f6ebffdfe5"
      },
      "source": [
        "# Observed that the output layer is not 1 output , but somehow related to our token count.\n",
        "model_1.summary()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_5 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15, 1)             129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahw1_AM-u2yq"
      },
      "source": [
        "# Build model with the functional API\n",
        "\n",
        "inputs = layers.Input(shape = (1,) , dtype = tf.string) # inputs are 1-D strings\n",
        "x = text_vectorizer(inputs) # turn the text into numbers\n",
        "x = embedding(x) # create an embedding \n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token\n",
        "outputs = layers.Dense(1 , activation = 'sigmoid')(x)\n",
        "model_1 = tf.keras.Model(inputs = inputs , outputs = outputs , name ='model_1')"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRWn8vgovCyR",
        "outputId": "3558c4d4-9041-495d-c96b-68a30033be3b"
      },
      "source": [
        "# Observed that after passing through the Pooling1D , the feature vector for each token is condense into 1 output\n",
        "model_1.summary()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_5 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aJ2Bbc6ru2i",
        "outputId": "5a9438b0-ffb6-4b75-ed24-d179e3fb5d1a"
      },
      "source": [
        "# Tensorboard Save directory\n",
        "save_dir = 'model_logs'\n",
        "\n",
        "model_1.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics = 'accuracy')\n",
        "\n",
        "history_1 = model_1.fit(train_sentences,\n",
        "                        train_label,\n",
        "                        epochs = 5,\n",
        "                        validation_data = (val_sentences, val_label),\n",
        "                        callbacks = [create_tensorboard_callback(dir_name = save_dir , \n",
        "                                                                 experiment_name = 'model_1_Dense')])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving Tensorboard log files to model_logs/model_1_Dense/20210826-183311\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 9ms/step - loss: 0.5632 - accuracy: 0.7662 - val_loss: 0.5215 - val_accuracy: 0.7664\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3969 - accuracy: 0.8536 - val_loss: 0.4630 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3156 - accuracy: 0.8822 - val_loss: 0.4497 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2629 - accuracy: 0.9028 - val_loss: 0.4576 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2235 - accuracy: 0.9219 - val_loss: 0.4712 - val_accuracy: 0.7900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RAgod49tEzo",
        "outputId": "898f6e7a-a65b-4125-83bc-a5ebf23930c6"
      },
      "source": [
        "# Model 1 Score\n",
        "model_1.evaluate(val_sentences , val_label)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4712037444114685, 0.7900262475013733]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgTEcb_AtmTK",
        "outputId": "830b895a-ff76-4704-abcb-d617e9b2a524"
      },
      "source": [
        "# Checking test_prediction with actual label\n",
        "model_1_preds = model_1.predict(val_sentences)\n",
        "print(f' Sample Test Prediction : {model_1_preds[-10:]}')\n",
        "print('----------------------')\n",
        "print(f' Actual Label : {val_label[-10:]}')"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sample Test Prediction : [[0.9894411 ]\n",
            " [0.03264952]\n",
            " [0.9403504 ]\n",
            " [0.6411978 ]\n",
            " [0.09302598]\n",
            " [0.2739401 ]\n",
            " [0.12194067]\n",
            " [0.75411695]\n",
            " [0.36215562]\n",
            " [0.01136661]]\n",
            "----------------------\n",
            " Actual Label : [1 0 1 1 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgCzTDUSuIBS",
        "outputId": "1c16e376-66e9-4771-91db-5873f514910a"
      },
      "source": [
        "# formatting test prediction to 0 and 1 format\n",
        "\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_preds))\n",
        "model_1_preds[:10]"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzmkjhUVwjTp",
        "outputId": "b3539c2c-9b26-43f3-a129-3daf5ce8adbb"
      },
      "source": [
        "model_1_results = eval_classification(val_label , model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.7900262467191601,\n",
              " 'F1 Score': 0.7460317460317459,\n",
              " 'Precision': 0.8333333333333334,\n",
              " 'Recall': 0.6752873563218391}"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JTfvkbzzJnB"
      },
      "source": [
        "### 1.5.1 Visualing via tensorflow projector\n",
        "___\n",
        "- [Tensorflow Projector](https://projector.tensorflow.org/)\n",
        "- [Word Embedding](https://www.tensorflow.org/text/guide/word_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8OoHRtpw-fB",
        "outputId": "2a038489-2c16-480b-e29e-881c75186b41"
      },
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab) , words_in_vocab[:10]"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncY1Mfrxx-E5",
        "outputId": "3c3eebec-81d0-4791-d870-451720c14bd3"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical representation of each token in our training data)\n",
        "# For every unique token or vocab , there is 128 vectors representing it.\n",
        "embed_weights = model_1.get_layer('embedding_2').get_weights()[0]\n",
        "embed_weights.shape"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE-cfiXCyihA"
      },
      "source": [
        "# Create Embedding files (we got this from Tensorflow's word embedding documentation)\n",
        "\n",
        "import io\n",
        "\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "IVBz_V530Eun",
        "outputId": "e75b866a-5e4d-4a45-eb0b-b891b008e74e"
      },
      "source": [
        "# Download file from Colab to upload to projector (we got this from Tensorflow's word embedding documentation)\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_19e8aaf3-7732-4da9-93f9-2b1662df407f\", \"vectors.tsv\", 15118769)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c27df7b2-7a4a-409f-8747-3191145668c7\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PLdT6zx3V-Z"
      },
      "source": [
        "<p align = 'center'>\n",
        "  Extract from Tensorflow Projector for Model_1 (Load Vector.tsv and metadata.tsv)\n",
        "  <img src = 'https://raw.githubusercontent.com/86lekwenshiung/Neural-Network-with-Tensorflow/main/images/08-tf_projector.png'>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoTsK9XG4CAu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Natural_Language_Processing in Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMCj4FID6JtjmT+ZqApHoNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/86lekwenshiung/Neural-Network-with-Tensorflow/blob/main/07_Natural_Language_Processing_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eim5-c54xWMJ"
      },
      "source": [
        "# 0.0 Natural Language Processing in Tensorflow\n",
        "___\n",
        "\n",
        "The main goal of natural language processing (NLP) is to derive information from natural language.\n",
        "Natural language is a broad term but you can consider it to cover any of the following:\n",
        "* Text (such as that contained in an email, blog post, book, Tweet)\n",
        "* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
        "\n",
        "**What is NLP used for?**\n",
        "\n",
        "Natural Language Processing is the driving force behind the following common applications:\n",
        "* Language translation applications such as Google Translate\n",
        "* Word Processors such as Microsoft Word and Grammarly that employ NLP to check grammatical accuracy of texts.\n",
        "* Interactive Voice Response (IVR) applications used in call centers to respond to certain users’ requests.\n",
        "* Personal assistant applications such as OK Google, Siri, Cortana, and Alexa.\n",
        "\n",
        "**Workflow**\n",
        "```\n",
        "Download text -> Visualize Text -> turn into numbers (tokenization , embedding) -> build a model -> train the model to find patterns -> compare model -> ensemble model\n",
        "```\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems(seq2seq)\n",
        "\n",
        "**Typical Architecture of a RNN**\n",
        "\n",
        "| Hyperparameter/Layer type | What does it do? | Typical values |\n",
        "|---|---|---|\n",
        "| Input text(s) | Target texts/sequences you'd like to discover patterns in | Whatever you can represent as text or a sequence |\n",
        "| Input layer | Takes in target sequence | input_shape = [batch_size, embedding_size] or [batch_size , sequence_shape] |\n",
        "| Text Vectorisation layer | Maps input sequence to layers | Multiple, can create with tf.keras.layers.preprocessing.TextVectorisation |\n",
        "| Embedding | Turn mapping of text vectors to embedding matrix | Multiple, can create with tf.keras.layers.Embedding |\n",
        "| RNN Cells | Find Pattern in Sequences | SimpleRNN , LSTM , GRU |\n",
        "| Hidden activation | Adds non-linearity to learned features (non-straight lines) | Usually Tanh (tf.keras.activations.tanh) |\n",
        "| Pooling layer | Reduces the dimensionality of learned image features | Average (tf.keras.layers.GlobalAveragePooling1D) or Max (tf.keras.layers.GlobalMaxPool1D) |\n",
        "| Fully connected layer | Further refines learned features from convolution layers | tf.keras.layers.Dense |\n",
        "| Output layer | Takes learned features and outputs them in shape of target labels | output_shape = [number_of_classes] (e.g. disaster , Not Disaster) |\n",
        "| Output activation | Adds non-linearities to output layer | tf.keras.activations.sigmoid (binary classification) or tf.keras.activations.softmax |\n",
        "\n",
        "\n",
        "`source` : \n",
        "* https://towardsdatascience.com/whatnlpscientistsdo-905aa987c5c0\n",
        "* https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32\n",
        "* https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFzwy8N6F6Go"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmsa-gdhyC96"
      },
      "source": [
        "# 1.0 Getting Data from kaggle (Natural Language Processing with Disaster Tweets)\n",
        "___\n",
        "\n",
        "source : https://www.kaggle.com/philculliton/nlp-getting-started-tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqcke9JRFHR1",
        "outputId": "1620b366-2aad-4602-abca-6b4c167361e7"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-26 10:05:42--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.193.128, 172.217.204.128, 172.217.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.193.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-08-26 10:05:42 (60.6 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr-wTtW6F4CP"
      },
      "source": [
        "# Unzip file\n",
        "zip_ref = zipfile.ZipFile('nlp_getting_started.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJbl6bVkGPlB"
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjCOXeq2paFC"
      },
      "source": [
        "### 1.1 Visualising Data\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "KIwlOi_PGx-g",
        "outputId": "b82bf314-1754-4ab6-aa1c-d37984fce959"
      },
      "source": [
        "# Checking Training Data\n",
        "df_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Gh3_6aYfiWDp",
        "outputId": "48715886-41ff-46d1-c5a5-303a2a14dfdf"
      },
      "source": [
        "df_train = df_train.sample(frac = 1 , random_state = 42)\n",
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SruLz4mQGy24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f801bb9a-1ca1-49ed-befe-6a0fd42990d7"
      },
      "source": [
        "# Checking Test Data\n",
        "df_test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-_KqfbyiPap",
        "outputId": "01bea347-7419-4da9-aac4-48bd03374320"
      },
      "source": [
        "# Target True : False Ratio\n",
        "df_train['target'].value_counts(normalize = True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.57034\n",
              "1    0.42966\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "lX2gUbWPltwJ",
        "outputId": "99077be9-2921-457a-8805-f36b24515c22"
      },
      "source": [
        "random_index = random.randint(0 , len(df_train))\n",
        "df_train[['text' , 'target']].head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  target\n",
              "2644  So you have a new weapon that can cause un-ima...       1\n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0\n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1\n",
              "132   Aftershock back to school kick off was great. ...       0\n",
              "6845  in response to trauma Children of Addicts deve...       0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb6c_PEhjDTZ",
        "outputId": "d5c819ec-5f59-41a0-abdb-85282b43c685"
      },
      "source": [
        "random_index = random.randint(0 , len(df_train))\n",
        "\n",
        "for row in df_train[['text' , 'target']][random_index : random_index +5].itertuples():\n",
        "  _ , text , target = row\n",
        "\n",
        "  print(f\"Target: {target}\" , \"(Disaster)\" if target > 0 else \"(Not Disaster)\")\n",
        "  print(f'Text: {text}')\n",
        "  print('-------\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0 (Not Disaster)\n",
            "Text: Bright &amp; BLAZING Fireman Birthday Party http://t.co/9rFo9GY3nE #Weddings\n",
            "-------\n",
            "\n",
            "Target: 0 (Not Disaster)\n",
            "Text: I wanna tweet a 'niall thx for not making me was to electrocute myself' tweet but I'm scared I'll jinx it\n",
            "-------\n",
            "\n",
            "Target: 1 (Disaster)\n",
            "Text: @aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.\n",
            "-------\n",
            "\n",
            "Target: 0 (Not Disaster)\n",
            "Text: Just burned the shit outta myself on my dirt bike ??\n",
            "-------\n",
            "\n",
            "Target: 0 (Not Disaster)\n",
            "Text: @FEVWarrior -in the Vault that could take a look at those wounds of yours if you'd like to go to one of these places first.' Zarry has had-\n",
            "-------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz18FeIVjwGH"
      },
      "source": [
        "### 1.2 Data Split Training and Validation\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUrB2HkjqMWi"
      },
      "source": [
        "# Define X and y variables\n",
        "train = df_train['text'].to_numpy()\n",
        "val = df_train['target'].to_numpy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF9ODPAKpoVy"
      },
      "source": [
        "train_sentences , val_sentences ,train_label , val_label = train_test_split(train , val , test_size = 0.1 , random_state  = 42)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIEaw6E2qrzS",
        "outputId": "07ec01e5-ad77-4434-9084-4bf61b55f078"
      },
      "source": [
        "print(f'Train Sentence: {train_sentences.shape}')\n",
        "print(f'Val Sentence: {val_sentences.shape}')\n",
        "print(f'Train Label: {train_label.shape}')\n",
        "print(f'Val Label: {val_label.shape}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Sentence: (6851,)\n",
            "Val Sentence: (762,)\n",
            "Train Label: (6851,)\n",
            "Val Label: (762,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxMdAYVZra8K"
      },
      "source": [
        "### 1.3 Converting Text into Numbers\n",
        "___\n",
        "\n",
        "* Tokenization : Straight mapping from token to number , however model can get very big as no. of words increases.\n",
        "* Embedding : Representation by vector , weighted matrix. Richer representation of relationship between tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X4mYslKCiwv"
      },
      "source": [
        "#### 1.3.1 Tokenization\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ShPUeyvrsJi"
      },
      "source": [
        "# # Default Setting of TextVectorisation\n",
        "# text_vectorizer = TextVectorization(max_tokens = None,\n",
        "#                                     standardize = 'lower_and_strip_punctuation',\n",
        "#                                     split = 'whitespace',\n",
        "#                                     ngrams = None, # grouping of words\n",
        "#                                     output_mode = 'int',\n",
        "#                                     output_sequence_length = None,\n",
        "#                                     pad_to_max_tokens = True) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "las3jVye85oo"
      },
      "source": [
        "# Setting up text vectorisation variables\n",
        "\n",
        "max_vocab_length = 10000  # Max number of words in our vocab\n",
        "max_length = 15 # max length our sequence will be (In this case the sequence is a tweet)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length = max_length,\n",
        "                                    pad_to_max_tokens = True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQk2DAEIAU3o",
        "outputId": "7fd98e58-a00f-4eed-b6e1-5e465c3caa5e"
      },
      "source": [
        "# Our max_length is set as 15 and our sentence only have 7 words. The rest of the 8 remaining wordss are padded with 0s.\n",
        "sample_sentence = 'There is a flood in Bukit Timah'\n",
        "text_vectorizer(sample_sentence)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15,), dtype=int64, numpy=\n",
              "array([ 74,   9,   3, 232,   4,   1,   1,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw94BLWBA2OO",
        "outputId": "98d6bfee-73b5-4420-e430-5eb03072803e"
      },
      "source": [
        "# Visualing random sentence from our training dataset.\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Originial Sentence: {random_sentence}')\n",
        "print('--------')\n",
        "print(f'Vectorized Sentence: {text_vectorizer(random_sentence)}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Originial Sentence: Im so anxious though because so many ppl will me watching me meet them and that makes me uncomfortable BUT I CANT LET THAT RUIN THE MOMENT\n",
            "--------\n",
            "Vectorized Sentence: [  32   28 4142  804  152   28  123  929   38   31  636   31 1389   93\n",
            "    7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCvRLlvsBtxI",
        "outputId": "31a8e329-4b4d-4e8e-9adb-2c3d0c026495"
      },
      "source": [
        "# Checking the unique vocabulary\n",
        "word_in_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f'Top 10 words: {word_in_vocab[:10]}')\n",
        "print(f'Bottom 10 words: {word_in_vocab[-10:]}')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 words: ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is']\n",
            "Bottom 10 words: ['painthey', 'painful', 'paine', 'paging', 'pageshi', 'pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGOqIUle_jbh"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkIGwXxaANpc"
      },
      "source": [
        "#### 1.3.2 Embedding\n",
        "___\n",
        "\n",
        "* Key Parameters for embedding layer:\n",
        "  - `input_dim` = size of our vocab\n",
        "  - `output_dim` = size of our output embedding vector. A value of 100 would mean each token get represented by a vector 100 long\n",
        "  - `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on_rl4ZmeQAy",
        "outputId": "3bc7e45d-44bc-4202-daef-8b5ebf06ddf6"
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim = max_vocab_length,\n",
        "                                      output_dim = 128,\n",
        "                                      input_length = max_length)\n",
        "embedding"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fe9a35fae90>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX1styRUennc",
        "outputId": "1f21999a-6e29-4a7b-b217-165042e79907"
      },
      "source": [
        "# Visualing random sentence from our training dataset.\n",
        "random_sentence = random.choice(train_sentences)\n",
        "\n",
        "print(f'Original Sentence : {random_sentence}')\n",
        "print('--------')\n",
        "print(f'Embedded Sentence : {embedding(text_vectorizer(random_sentence)).shape}')\n",
        "print(f'Embedded Sentence : {embedding(text_vectorizer(random_sentence))}')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence : I don't pray harm on members of ISIS.I pray they experience the life-rebooting love of God &amp; become 'Paul's' in Gods mind-blowing final Act\n",
            "--------\n",
            "Embedded Sentence : (15, 128)\n",
            "Embedded Sentence : [[-0.00283871  0.0118186   0.02091951 ... -0.01730181 -0.04164167\n",
            "   0.00070925]\n",
            " [ 0.02597681 -0.01401955  0.02378706 ... -0.04332544  0.03536881\n",
            "  -0.01831583]\n",
            " [-0.04824638  0.00782424  0.00272657 ... -0.00690223  0.03945352\n",
            "  -0.03128378]\n",
            " ...\n",
            " [ 0.04091967 -0.03550221  0.04409833 ...  0.02903645  0.03072219\n",
            "  -0.00509418]\n",
            " [ 0.04361527  0.01893303  0.0297743  ...  0.02776686  0.03634677\n",
            "   0.03193242]\n",
            " [-0.04824767 -0.02490045 -0.04372081 ...  0.04281325  0.00329584\n",
            "   0.01509192]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc53FaxCetLs"
      },
      "source": [
        "### 1.4 Model 0 : Baseline Model with Naive Bayes with TF_IDF encoder\n",
        "___\n",
        "\n",
        "* Model 0 : Naive Bayes with TF-IDF encoder\n",
        "* Model 1 : Feed-Forward neural network (dense)\n",
        "* Model 2 : LSTM model (RNN)\n",
        "* Model 3 : GRU model (RNN)\n",
        "* Model 4 : Bidirectional - LSTM model (RNN)\n",
        "* Model 5 : 1D CNN\n",
        "* Model 6 : TF Hub Pretrained Feature Extractor\n",
        "* Model 7 : TF Hub Pretrained Feature Extractor with 10% data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHEHOnNviKPo"
      },
      "source": [
        "# Model 0 : Import Libraries\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6MvfWqqjGUL",
        "outputId": "a5929040-2f8c-4e9e-f6b8-9fcab8c37507"
      },
      "source": [
        "model_0 = Pipeline([\n",
        "                    ('tfidf' , TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    ('clf' , MultinomialNB()) #model the text\n",
        "])\n",
        "\n",
        "model_0.fit(train_sentences , train_label)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kSED-LejjpK"
      },
      "source": [
        "# Baseline model score\n",
        "model_0.score(val_sentences , val_label)\n",
        "model_0_preds = model_0.predict(val_sentences)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubkBSvK9ju1b"
      },
      "source": [
        "def eval_classification(y_true , y_pred):\n",
        "\n",
        "  from sklearn.metrics import accuracy_score , precision_score , recall_score , f1_score\n",
        "\n",
        "  # Define Scoring variables\n",
        "  accuracy = accuracy_score(y_true , y_pred)\n",
        "  precision = precision_score(y_true , y_pred)\n",
        "  recall = recall_score(y_true , y_pred)\n",
        "  f1_score = f1_score(y_true , y_pred)\n",
        "\n",
        "  score_dict = {'Accuracy' : accuracy,\n",
        "                'Precision' : precision,\n",
        "                'Recall' : recall,\n",
        "                'F1 Score' : f1_score}\n",
        "\n",
        "  return score_dict"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFvNGMtfl5aj",
        "outputId": "4d25e5a7-decf-48d6-c00a-2d7c3f70f7c8"
      },
      "source": [
        "eval_classification(y_true = val_label , y_pred = model_0_preds)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.7926509186351706,\n",
              " 'F1 Score': 0.734006734006734,\n",
              " 'Precision': 0.8861788617886179,\n",
              " 'Recall': 0.6264367816091954}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYL7vKHCmAk6"
      },
      "source": [
        "### 1.5 Model 1 : Feed Forward Neural Network\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8frA0hfog6a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}